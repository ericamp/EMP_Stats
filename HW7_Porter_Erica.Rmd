---
title: "HW7_Porter_Erica"
output:
  pdf_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = "h")
library(stargazer)
library(data.table)
library(lubridate)
library(lintr)
library(data.table)
library(knitr)
library(foreach)
library(doParallel)
library(doRNG)
library(doMC)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = T, message = F, warning = F)
```

```{r Problem2_sum_squares, echo = F, eval = T, include = T}
## Problem 2: calculating sum of squares ##

# generate data
set.seed(12345)
y <- rnorm(n = 1e+05, mean = 1, sd = 1)


# Part A: calculate sum of squares with summation and for loop (record time)

sum_sq <- 0
n <- length(y)
diff_sq <- rep(0, n)
y_avg <- mean(y)

time1 <- system.time({
    for (i in 1:n) {
    diff_sq[i] <- (y[i] - y_avg)^2
    sum_sq = sum_sq + diff_sq[i]
    }
})


# Part B: calculate sum of squares using vector operations (record time)

SS <- 0     # initialize

time2 <- system.time({
    SS <- t(y - y_avg) %*% (y - y_avg)
})

# Part C: parallelize sum of squares using %dopar% (record time)

c1 <- makeCluster(2)  
registerDoParallel(c1)
time3 <- system.time({
    SS1 <- foreach(i = 1:n, .combine = "+") %dopar%  {(y[i] - y_avg)^2}
})

stopCluster(c1)


# Part D: parallel sum of squares using parSapply instead (record time)

sum_fun <- function(y) {((y - y_avg)^2)}

cluster2 <- makeCluster(2); registerDoParallel(cluster2)
clusterExport(cluster2, c("sum_fun", "y_avg"))
time4 <- system.time({SS2 <- sum(parSapply(cluster2, 1:n, function(y) sum_fun(y)))
    
})
stopCluster(cluster2)


# Chart of final answers and times
answers <- c(sum_sq, SS, SS1, SS2)
elapsed <- c(time1[3], time2[3], time3[3], time4[3])
system <- c(time1[2], time2[2], time3[2], time4[2])
user <- c(time1[1], time2[1], time3[1], time4[1])
compare_times <- cbind(answers, elapsed, system, user)
colnames(compare_times) <- c("SST calculation", "Elapsed", "System", "User")
knitr::kable(compare_times)
```

```{r Problem3_parallelize, echo = F, eval = T, include = T}
# Problem 3: parallelize matrix

# given data
set.seed(1256)
theta <- as.matrix(c(1, 2), nrow = 2) 
X <- cbind(1, rep(1:10, 10))
h <- X %*% theta + rnorm(100, 0, 0.2)

# We could potentially parallelize the objects that we define (e.g. alpha, tolerance, initial theta matrix)
# Process I used last homework
first_theta <- matrix(0, nrow = 2)
alpha = 0.01
tol = 10e-05
m <- length(h)

for (i in 1:m) {
while (abs(theta[2] - first_theta[2]) > tol && abs(theta[1] - first_theta[1]) > tol) {
    
    first_theta[1] <- theta[1] - (alpha * (1/m)) * sum(first_theta[1] + first_theta[2] * X[i,2] - h[i])
    first_theta[2] <- theta[2] - (alpha * (1/m)) * sum((theta[1] + theta[2] * X[i,2] - h[i]) * X[i,2])
    
}}
```

```{r hopeless_attempt, echo - F, eval = T}
set.seed(1256)
    theta <- as.matrix(c(1,2), nrow =2)
    X <- cbind(1, rep(1:10,10))
    h <- X %*% theta + rnorm(100,0,0.2)
    
    theta_current <- as.matrix(c(0,0), nrow =2)
    theta_new <- as.matrix(c(1,1), nrow =2)
    alpha <- 0.0001
    tolerance <- 0.000001
    m <- length(h)
    
    tX <- t(X)
    t5 <- system.time({
    while(sum(abs(theta_new-theta_current)>tolerance)){
            theta_current <- theta_new
            theta_grad <- tX %*% ((X %*% theta_current) - h)
            theta_new <- theta_current - alpha/m * theta_grad
    }
    })
```

```{r Probelm4_bootstrap, echo = F, eval = T, include = T}
# Problem 4: random sample using boostrap method

# Algorithm outline:
# For 1:B, sample points Z^b
# Calculate B^b estimates

# given data
n <- 200
X <- 1/cbind(1, rt(n, df = 1), rt(n, df = 1), rt(n, df = 1))
beta <- c(1, 2, 3, 0)
Y <- X %*% beta + rnorm(100, sd = 3)

# Bootstrap sample without parallelization
B <- 10000
q <- length(beta)
beta_boot <- matrix(0, nrow = B, ncol=q)   # initialize matrix of zeros to hold sample
index_boot <- matrix(0, B, 1)

for (b in 1:B) {
index_boot <- sample(1:n, n, replace = T)
X_boot <- X[index_boot,]
Y_boot <- Y[index_boot,]
beta_boot <- coef(lm(Y_boot ~ X_boot))  # Now for beta estimates
}


n <- 200
X <- 1/cbind(1, rt(n, df = 1), rt(n, df = 1), rt(n, df = 1))
beta <- c(1, 2, 3, 0)
Y <- X %*% beta + rnorm(100, sd = 3)

B <- 10000
q <- length(beta)
beta_boot <- matrix(0, nrow = B, ncol=q)   
index_boot <- matrix(0, B, 1)

c4 <- makeCluster(2)
registerDoParallel(c4)
#use cbind as the .combine
# use doRNG in place of dopar
foreach(i = 1:B, .combine = "cbind") %dorng% {
    index_boot <- sample(1:n, n, replace = T)
    X_boot <- X[index_boot,]
    Y_boot <- Y[index_boot,]
    beta_boot[b,] <- coef(lm(Y_boot ~ X_boot))
}

stopCluster(c4)
```

