---
title: "HW7_Porter_Erica"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = "h")
library(stargazer)
library(data.table)
library(lubridate)
library(lintr)
library(data.table)
library(knitr)
library(foreach)
library(doParallel)
library(doRNG)
library(doMC)
library(stats)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = T, message = F, warning = F)
```

#Problem 1 
I created a new repository with the name EMP_Stats under my username, ericamp.  The link to my new repository is https://github.com/ericamp/EMP_Stats

#Problem 2: Sum of Squares
The objective of this problem is to calculate sums of squares four different ways.

For loop: calculate sum of squares with the same natural process as the formula $S_{xx} = \sum_{i=1}^{n} (x_{i}-\bar{x})^{2} = \sum_{i=1}^{n} x_{i}^{2} - \frac{(\sum_{i=1}^{n} x_{i})^{2}}{n}$

Vector operations: use the same process as the for loop, replacing exponentiation with the %*% operator, eliminating the need for indices to iterate on.

Foreach: parallelize the sum of squares calculation with $\texttt{foreach}$; works very similarly to the for loop, but the $\texttt{foreach}$ command tabkes both $\texttt{.combine}$ and an index.

parSapply: write a function and pass this to $\texttt{parSapply}$ to perform a set number of times without need for an index.

Below are the parallelized sum of squares operations that were not included/requested in HW6.
```{r, echo = T, eval = F, include = T}
# Part C: %dopar% calculation

c1 <- makeCluster(2); registerDoParallel(c1)
time3 <- system.time({
    SS1 <- foreach(i = 1:n, .combine = "+") %dopar%  {(y[i] - y_avg)^2}
})

stopCluster(c1)

# Part D: parSapply calculation

sum_fun <- function(y) {((y - y_avg)^2)}

cluster2 <- makeCluster(2); registerDoParallel(cluster2)
clusterExport(cluster2, c("sum_fun", "y_avg"))
time4 <- system.time({SS2 <- sum(parSapply(cluster2, 1:n, function(y) sum_fun(y)))
    
})
stopCluster(cluster2)
```

```{r Problem2_sum_squares, echo = F, eval = T, include = T}
## Problem 2: calculating sum of squares ##

# generate data
set.seed(12345)
y <- rnorm(n = 1e+05, mean = 1, sd = 1)


# Part A: calculate sum of squares with summation and for loop (record time)

sum_sq <- 0
n <- length(y)
diff_sq <- rep(0, n)
y_avg <- mean(y)

time1 <- system.time({
    for (i in 1:n) {
    diff_sq[i] <- (y[i] - y_avg)^2
    sum_sq = sum_sq + diff_sq[i]
    }
})


# Part B: calculate sum of squares using vector operations (record time)

SS <- 0     # initialize

time2 <- system.time({
    SS <- t(y - y_avg) %*% (y - y_avg)
})

# Part C: parallelize sum of squares using %dopar% (record time)

c1 <- makeCluster(2)  
registerDoParallel(c1)
time3 <- system.time({
    SS1 <- foreach(i = 1:n, .combine = "+") %dopar%  {(y[i] - y_avg)^2}
})

stopCluster(c1)


# Part D: parallel sum of squares using parSapply instead (record time)

sum_fun <- function(y) {((y - y_avg)^2)}

cluster2 <- makeCluster(2); registerDoParallel(cluster2)
clusterExport(cluster2, c("sum_fun", "y_avg"))
time4 <- system.time({SS2 <- sum(parSapply(cluster2, 1:n, function(y) sum_fun(y)))
    
})
stopCluster(cluster2)


# Chart of final answers and times
answers <- c(sum_sq, SS, SS1, SS2)
elapsed <- as.vector(c(time1[3], time2[3], time3[3], time4[3]))
system <- as.vector(c(time1[2], time2[2], time3[2], time4[2]))
user <- as.vector(c(time1[1], time2[1], time3[1], time4[1]))
label <- c("for loop","vector","foreach","parSapply")
compare_times <- cbind(label,answers, elapsed, system, user)
colnames(compare_times) <- c("Method", "SST calculation", "Elapsed", "System", "User")
knitr::kable(compare_times)
```

#Problem 3: Gradient Descent

The inputs that we define/intitialize are tolerance, alpha, and the initial $\Theta$ matrix, so it seems best to parallelize based upon one of these values (e.g. different possible $\alpha$'s, different possible $\Theta$'s).


```{r, Prob3, echo = F, eval = T}
# given data
set.seed(1256)
theta <- as.matrix(c(1, 2), nrow = 2) 
X <- cbind(1, rep(1:10, 10))
h <- X %*% theta + rnorm(100, 0, 0.2)
```

```{r Problem3_parallelize, echo = T, eval = T, include = T}
# Problem 3: parallelize matrix

# Wrapping around process I used last homework
first_theta <- matrix(0, nrow = 2)
alpha = 0.01
tol = 10e-03
m <- length(h)

# changing alpha seems easier, although potentially unhelpful
ca <- makeCluster(2)  
registerDoParallel(ca)
alpha_vec <- seq(0, 0.1, 0.01)
foreach(a = 1:11, .combine = "c") %dopar% {
    alpha <- alpha_vec[a]
for (i in 1:m) {
while (abs(theta[2] - first_theta[2]) > tol && abs(theta[1] - first_theta[1]) > tol) {
    
    first_theta[1] <- theta[1] - (alpha * (1/m)) * sum(first_theta[1] + first_theta[2] * X[i,2] - h[i])
    first_theta[2] <- theta[2] - (alpha * (1/m)) * sum((theta[1] + theta[2] * X[i,2] - h[i]) * X[i,2])

    }}
}
stopCluster(ca)

#xseq <- seq(0,1,0.1)
#result_grad <- foreach(j = xseq, .combine = "c") %dopar% {
for (i in 1:m) {
while (abs(theta[2] - first_theta[2]) > tol && abs(theta[1] - first_theta[1]) > tol) {
    
    first_theta[1] <- theta[1] - (alpha * (1/m)) * sum(first_theta[1] + first_theta[2] * X[i,2] - h[i])
    first_theta[2] <- theta[2] - (alpha * (1/m)) * sum((theta[1] + theta[2] * X[i,2] - h[i]) * X[i,2])
    
}}
#}
```

```{r hopeless_attempt, echo = F, eval = T}

set.seed(1256)
    theta <- as.matrix(c(1,2), nrow =2)
    X <- cbind(1, rep(1:10,10))
    h <- X %*% theta + rnorm(100,0,0.2)
    
    theta_current <- as.matrix(c(0,0), nrow =2)
    theta_new <- as.matrix(c(1,1), nrow =2)
    alpha <- 0.0001
    tolerance <- 0.000001
    m <- length(h)
    
    tX <- t(X)
    t5 <- system.time({
    while(sum(abs(theta_new-theta_current)>tolerance)){
            theta_current <- theta_new
            theta_grad <- tX %*% ((X %*% theta_current) - h)
            theta_new <- theta_current - alpha/m * theta_grad
    }
    })
```


#Problem 4: Boostrap
Use $\texttt{foreach}$ to perform Boostrap on the given X and Y matrices and provide summary statistics for the resulting $\hat{\beta}^{(b)}$ values.

After inputing the given data, I did the following with $\texttt{foreach}$ and $\texttt{%dorng%}$.
```{r, echo = T, eval = F, include = T}
beta_boot <- matrix(NA, nrow = 10000, ncol = 4)
index_boot <- matrix(0, nrow = n, ncol = 1)
boot_result <- list()

c4 <- makeCluster(2)
registerDoParallel(c4)
registerDoRNG()
set.seed(1267)

boot_result <- foreach(b = 1:10000, .combine = "rbind") %dorng% {
    index_boot <- sample(1:n, n, replace = TRUE)
    X_boot <- X[index_boot,]
    Y_boot <- Y[index_boot]
    beta_boot <- coef(lm(Y_boot ~ 0 + X_boot))
    return(beta_boot)
}

stopCluster(c4)
```

```{r Probelm4_bootstrap, echo = F, eval = T, include = T}

# Problem 4: random sample using boostrap method

# given data
n <- 200
X <- 1/cbind(1, rt(n, df = 1), rt(n, df = 1), rt(n, df = 1))
beta <- c(1, 2, 3, 0)
Y <- X %*% beta + rnorm(100, sd = 3)
B <- 10000
q <- length(beta)

# use rbind as the .combine
# use doRNG in place of dopar

beta_boot <- matrix(NA, nrow = 10000, ncol = 4)
index_boot <- matrix(0, nrow = n, ncol = 1)
boot_result <- list()

c4 <- makeCluster(2)
registerDoParallel(c4)
registerDoRNG()
set.seed(1267)

boot_result <- foreach(b = 1:10000, .combine = "rbind") %dorng% {
    index_boot <- sample(1:n, n, replace = TRUE)
    X_boot <- X[index_boot,]
    Y_boot <- Y[index_boot]
    beta_boot <- coef(lm(Y_boot ~ 0 + X_boot))
    return(beta_boot)
}

stopCluster(c4)
#as.data.frame(boot_result)

knitr::kable(summary(as.data.frame(boot_result)))
par(mfrow = c(2,2))
hist(as.data.frame(boot_result)$X_boot1, xlab = "", main = "Beta1")
hist(as.data.frame(boot_result)$X_boot2, xlab = "", main = "Beta2")
hist(as.data.frame(boot_result)$X_boot3, xlab = "", main = "Beta3")
hist(as.data.frame(boot_result)$X_boot4, xlab = "", main = "Beta4")

```
\newpage

#Appendix
```{r Appendix, ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE}
```

